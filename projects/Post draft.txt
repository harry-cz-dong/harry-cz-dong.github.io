Insurers don't charge the same premium for all policyholders.
If they do, high risk individuals would be paying less relative to
their expected amount of claims, and low risk individuals more.
Thus this would incentivise riskier policyholders to sign up,
while low-risk policyholders would cancel their policies - death spiral
Therefore, insurers ideally want to segment their policyholders using
several different factors and predict their frequency and severity

Motor claims Australian data for a year. each entry has {Variables}
number of claims, claim amount

Initially 
Ideally the variables should be categorical rather than a continuous numeric variable. 
We don't need to focus on exact value of vehicle, group similar valued vehicles into
classes - "low, mid, high, very high" 
[Jenk's natural breaks]

Take a glance at frequency and severity across different segments.


GLM extends the linear regression model and allows the data points
to be drawn from a distribution other than a normal distribution. 
Frequency poisson, severity lognormal 


GLM attempts to fit points to minimise the sum of the square residuals
Problem: overfitting
Ridge GLM adds a penalty as the coefficients increase,
essentially encourages the model to shrink the weight it
puts on the predictors, and to produce a model that hones in
on a smaller set of useful, meaningful variables 

The lambda parameter controls how strongly it shrinks the coefficients.
Tuning by comparing the [cross-validated errors] of the models produced by
different values of lambda.

Predict on out-of-sample data that I put aside.

Total estimated premium = , actual loss = . Underestimation



Here is the graph (d3.js)
dotted underline with explanatory hover



